# -*- coding: utf-8 -*-
"""Pipeline za testiranje.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aBdVgN46oTZQGAazVxmXX1DUXzSJPATt

# Osnovni importi
"""

from __future__ import print_function, division
import warnings
warnings.filterwarnings("ignore")
import os.path
import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import dlib
import os
import argparse

"""# Otvaramo Google Drive na kojem nam se nalaze svi podaci i potrebni helper modeli"""

from google.colab import drive
drive.mount('/content/drive')

"""# Definiramo putanju na nasem Google Drive gdje nam se nalazi projekat"""

izuzetak = False

import os
putanja = '/content/drive/MyDrive/[VI projekat] Procjena sociobioloskih karakteristika na osnovu slike lica '
try:
  print(os.listdir(putanja))
except Exception as e:
  izuzetak = True
os.chdir(putanja)
print(izuzetak)

if izuzetak:
  !pip install -U -q PyDrive
  from pydrive.auth import GoogleAuth
  from pydrive.drive import GoogleDrive
  from google.colab import auth
  from oauth2client.client import GoogleCredentials

  # Autentifikacija
  auth.authenticate_user()
  gauth = GoogleAuth()
  gauth.credentials = GoogleCredentials.get_application_default()
  drive = GoogleDrive(gauth)

  # Ime foldera koji traÅ¾imo
  target_folder_name = '[VI projekat] Procjena sociobioloskih karakteristika na osnovu slike lica'

  # Pretraga shared-with-me sadrÅ¾aja
  file_list = drive.ListFile({
      'q': f"title = '{target_folder_name}' and mimeType = 'application/vnd.google-apps.folder' and sharedWithMe = true"
  }).GetList()

  if file_list:
      folder = file_list[0]
      print(f"âœ… Folder pronaÄ‘en: {folder['title']}")
      print(f"ðŸ“ ID foldera: {folder['id']}")
  else:
      print("âŒ Folder nije pronaÄ‘en u 'Shared with me'.")

"""# Fja koja od pravougaonika koji omedjuje lice kreira bounding box"""

def rect_to_bb(rect):
	# take a bounding predicted by dlib and convert it
	# to the format (x, y, w, h) as we would normally do
	# with OpenCV
	x = rect.left()
	y = rect.top()
	w = rect.right() - x
	h = rect.bottom() - y
	# return a tuple of (x, y, w, h)
	return (x, y, w, h)

"""# Funkcija koja uz pomoc pretrained dlib modela pronalazi lice na fotografiji"""

def detect_face(image_paths,  SAVE_DETECTED_AT, default_max_size=800,size = 300, padding = 0.25):
    cnn_face_detector = dlib.get_frontal_face_detector()

    sp = dlib.shape_predictor('dlib_models/shape_predictor_5_face_landmarks.dat')
    base = 2000  # largest width and height
    for index, image_path in enumerate(image_paths):
        if index % 1000 == 0:
            print('---%d/%d---' %(index, len(image_paths)))
        img = dlib.load_rgb_image(image_path)

        old_height, old_width, _ = img.shape

        if old_width > old_height:
            new_width, new_height = default_max_size, int(default_max_size * old_height / old_width)
        else:
            new_width, new_height =  int(default_max_size * old_width / old_height), default_max_size
        img = dlib.resize_image(img, rows=new_height, cols=new_width)

        dets = cnn_face_detector(img, 1)
        num_faces = len(dets)
        if num_faces == 0:
            print("Sorry, there were no faces found in '{}'".format(image_path))
            continue
        # Find the 5 face landmarks we need to do the alignment.
        faces = dlib.full_object_detections()
        for rect in dets:
          faces.append(sp(img, rect))
        images = dlib.get_face_chips(img, faces, size=size, padding = padding)
        for idx, image in enumerate(images):
            img_name = image_path.split("/")[-1]
            path_sp = img_name.split(".")
            face_name = os.path.join(SAVE_DETECTED_AT,  path_sp[0] + "_" + "face" + str(idx) + "." + path_sp[-1])
            dlib.save_image(image, face_name)

"""# Funkcija koja uz pomoc nasih modela koji su spremljeni na Google Drive-u radi predikciju karakteristika za slike koje se proslijede u csv-u"""

def predidct_age_gender_race(save_prediction_at, imgs_path = 'cropped_faces/'):
    img_names = [os.path.join(imgs_path, x) for x in os.listdir(imgs_path)]
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    model_fair_7 = torchvision.models.resnet34(pretrained=True)
    model_fair_7.fc = nn.Linear(model_fair_7.fc.in_features, 18)
    #model_fair_7.load_state_dict(torch.load('fair_face_models/fairface_alldata_20191111.pt'))
    #model_fair_7.load_state_dict(torch.load('./res34_fair_align_multi_7_20190809.pt'))
    model_fair_7.load_state_dict(torch.load('./modeli/nas_model5.pt'))
    model_fair_7 = model_fair_7.to(device)
    model_fair_7.eval()

    trans = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    # img pth of face images
    face_names = []
    # list within a list. Each sublist contains scores for all races. Take max for predicted race
    race_scores_fair = []
    gender_scores_fair = []
    age_scores_fair = []
    race_preds_fair = []
    gender_preds_fair = []
    age_preds_fair = []
    race_scores_fair_4 = []
    race_preds_fair_4 = []

    for index, img_name in enumerate(img_names):
        if index % 1000 == 0:
            print("Predicting... {}/{}".format(index, len(img_names)))

        face_names.append(img_name.split('dataset/', 1)[-1])
        image = dlib.load_rgb_image(img_name)
        image = trans(image)
        image = image.view(1, 3, 224, 224)  # reshape image to match model dimensions (1 batch size)
        image = image.to(device)

        # fair
        outputs = model_fair_7(image)
        outputs = outputs.cpu().detach().numpy()
        outputs = np.squeeze(outputs)

        race_outputs = outputs[:7]
        gender_outputs = outputs[7:9]
        age_outputs = outputs[9:18]

        race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))
        gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))
        age_score = np.exp(age_outputs) / np.sum(np.exp(age_outputs))

        race_pred = np.argmax(race_score)
        gender_pred = np.argmax(gender_score)
        age_pred = np.argmax(age_score)

        race_scores_fair.append(race_score)
        gender_scores_fair.append(gender_score)
        age_scores_fair.append(age_score)

        race_preds_fair.append(race_pred)
        gender_preds_fair.append(gender_pred)
        age_preds_fair.append(age_pred)

    result = pd.DataFrame([face_names,
                           race_preds_fair,
                           gender_preds_fair,
                           age_preds_fair,
                           race_scores_fair,
                           gender_scores_fair,
                           age_scores_fair, ]).T
    result.columns = ['file',
                      'race_preds_fair',
                      'gender_preds_fair',
                      'age_preds_fair',
                      'race_scores_fair',
                      'gender_scores_fair',
                      'age_scores_fair']
    result.loc[result['race_preds_fair'] == 0, 'race'] = 'White'
    result.loc[result['race_preds_fair'] == 1, 'race'] = 'Black'
    result.loc[result['race_preds_fair'] == 2, 'race'] = 'Latino_Hispanic'
    result.loc[result['race_preds_fair'] == 3, 'race'] = 'East Asian'
    result.loc[result['race_preds_fair'] == 4, 'race'] = 'Southeast Asian'
    result.loc[result['race_preds_fair'] == 5, 'race'] = 'Indian'
    result.loc[result['race_preds_fair'] == 6, 'race'] = 'Middle Eastern'

    # gender
    result.loc[result['gender_preds_fair'] == 0, 'gender'] = 'Male'
    result.loc[result['gender_preds_fair'] == 1, 'gender'] = 'Female'

    # age
    result.loc[result['age_preds_fair'] == 0, 'age'] = '0-2'
    result.loc[result['age_preds_fair'] == 1, 'age'] = '3-9'
    result.loc[result['age_preds_fair'] == 2, 'age'] = '10-19'
    result.loc[result['age_preds_fair'] == 3, 'age'] = '20-29'
    result.loc[result['age_preds_fair'] == 4, 'age'] = '30-39'
    result.loc[result['age_preds_fair'] == 5, 'age'] = '40-49'
    result.loc[result['age_preds_fair'] == 6, 'age'] = '50-59'
    result.loc[result['age_preds_fair'] == 7, 'age'] = '60-69'
    result.loc[result['age_preds_fair'] == 8, 'age'] = 'more than 70'

    result[['file',
            'race',
            'gender', 'age',
            'race_scores_fair',
            'gender_scores_fair', 'age_scores_fair']].to_csv(save_prediction_at, index=False)

    print("saved results at ", save_prediction_at)

"""# Funkcija koja osigurava da smo u ispravnom direktoriju"""

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

"""# Pipeline za testiranje rezultata koji prima csv sa putanjama slika i ime output csv-a"""

# face_pipeline.py

import dlib
import pandas as pd
import glob

# turn off CUDA if you want
dlib.DLIB_USE_CUDA = True

def run_pipeline(output_csv: str, save_dir: str = "detected_faces"):
    image_dir = os.path.join(putanja, "dataset", "val")

    # 1) Read CSV of image paths
    safe_dir = glob.escape(image_dir)
    imgs = [f for f in glob.glob(os.path.join(safe_dir, "*")) if f.lower().endswith((".jpg", ".jpeg", ".png"))]

    print(f"Found {len(imgs)} images in {image_dir}")

    # 3) Predict age/gender/race
    predidct_age_gender_race(output_csv, image_dir)

"""# Predikcije za testni skup"""

output_csv = putanja + "/rezultati/our_fairface_label_val_novo.csv"
run_pipeline(output_csv)

"""# Iscrtavanje matrica konfuzije i dodatnih metrika za dobijene rezultate"""

# Install scikit-learn if needed
!pip install -q scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score
import re

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TRUE_CSV = putanja + "/rezultati/fairface_label_val.csv"
PRED_CSV = putanja + "/rezultati/our_fairface_label_val.csv"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1) Load
df_true = pd.read_csv(TRUE_CSV)
df_pred = pd.read_csv(PRED_CSV)

for param in ['gender','race','age']:
    # 2) Basic checks
    for name, df in (("TRUE", df_true), ("PRED", df_pred)):
        if 'file' not in df.columns:
            raise KeyError(f"{name}_CSV missing a 'file' column")
        if param not in df.columns:
            raise KeyError(f"{name}_CSV missing a {param} column")

    # 3) Inner join on 'file'
    df_merged = pd.merge(
        df_true[['file',param]].rename(columns={param:f'{param}_true'}),
        df_pred[['file',param]].rename(columns={param:f'{param}_pred'}),
        on='file',
        how='inner'
    )
    total = len(df_merged)
    print(f"\n=== {param.upper()} ===")
    print(f"Matched rows: {total} (out of {len(df_true)} true / {len(df_pred)} pred)")

    # 4) Extract y_true, y_pred
    y_true = df_merged[f'{param}_true'].astype(str)
    y_pred = df_merged[f'{param}_pred'].astype(str)

    # 4a) Compute raw labels
    raw_labels = np.unique(np.concatenate([y_true.unique(), y_pred.unique()]))

    # 4b) If age, sort by numeric lower bound
    if param == 'age':
        def age_key(s):
            m = re.match(r'(\d+)', s)
            return int(m.group(1)) if m else float('inf')
        labels = sorted(raw_labels, key=age_key)
    else:
        labels = sorted(raw_labels)

    # 4c) Confusion matrix
    cm = confusion_matrix(y_true, y_pred, labels=labels)

    # 4d) Accuracy
    correct = np.trace(cm)
    accuracy = correct / total if total > 0 else 0.0
    print(f"Accuracy: {accuracy*100:.2f}% ({correct}/{total})")

    # 4e) Weighted F1-score
    f1 = f1_score(y_true, y_pred, labels=labels, average='weighted')
    print(f"Weighted F1-score: {f1:.4f}")

    # 5) Plot inline
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
    fig, ax = plt.subplots(figsize=(6,6))
    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')
    ax.set_title(f"{param.capitalize()} Confusion Matrix\nAccuracy: {accuracy*100:.1f}%, F1: {f1:.3f}")
    plt.tight_layout()
    plt.savefig(f"{putanja}/rezultati/{param}_confusion_matrix.pdf")
    plt.show()